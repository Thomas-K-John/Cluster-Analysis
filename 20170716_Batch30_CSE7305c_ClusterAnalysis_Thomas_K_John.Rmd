---
title: "Cluster Analysis for Crime Data"
author: "Clustering INSOFE Lab Assignment"
date: "16 July 2017"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: yes
---

**NOTE** Before starting this assignment please remember to clear your environment, you can do that by running the following code chunk

```{r}
rm(list = ls(all = TRUE))

```

# Agenda

* Get the data

* Data pre-processing

* Explore the data

* Hierarchical Clustering

* Kmeans Clustering

* Visualising Clusters and Evaluation


# Problem Description

* In the following Unsupervised Learning activity, you will perform cluster analysis on a dataset that has arrests per 100,000 residents for assault, murder, and rape in each of the 50 US states

* The variable names in the dataset are self explanatory

* So, you will cluster US states based on the crime rates, which can then be passed on to public policy experts to gain insight from it


# Reading & Understanding the Data

* Read in the dataset

```{r}

# Use the setwd() function to get to the directory where the data is present
setwd("I:/DATA-SCIENCE/Insofe/Assignments/Cluster-Analysis")
crime.data = read.csv("crime_data.csv", header = TRUE )

```

* Use the str() and summary() functions to get a feel for the dataset.

```{r}
str(crime.data)
summary(crime.data)

```

* Take a look at the data using the "head()" and "tail()" functions

```{r}
head(crime.data)
tail(crime.data)

```

# Data pre-processing

* Check for the number of missing values in the dataset

```{r}
sum(is.na(crime.data))
```


* Convert the State names into row names and remove that variable from the dataset

```{r}
rownames(crime.data) = crime.data$State
crime.data$State = NULL



```

* Standardize and scale the data

```{r}
scaled.crime.data = scale(crime.data, center = TRUE, scale = TRUE)

```

# Data exploration

* Visualise the distances between the individual observations using the fviz_dist()

```{r, fig.width=12, fig.height=8}

library(factoextra)
distance = get_dist(scaled.crime.data)
fviz_dist(distance, gradient = list(low= "green", mid = "white", high="blue"))

```

# Hierarchical Clustering

* Cluster the data using the Ward algorithm

```{r}

hc.data = hclust(distance, method = "ward.D2")

```

* Plot the dendogram for hierarchical clustering

```{r, fig.height=5, fig.width=10}

plot(hc.data)

```

* Cut the tree to 4 clusters

```{r}

points.tree = cutree(hc.data, k = 4)

```

* Plot a new dendogram, with each of the clusters being surrounded by a border, using the rect.hclust() function

```{r, fig.height=5, fig.width=10}
plot(hc.data)
rect.hclust(hc.data, k= 4, border = "red")

```


# K-Means Clustering

* Build a basic kmeans model with k = 2

```{r}

set.seed(123)
k.means.cluster = kmeans(scaled.crime.data, centers = 2)

```

* Build a scree plot and choose a "k"

```{r}
wss = 0
for(i in 1:10){
  fit = kmeans(scaled.crime.data, centers = i)
  wss[i] = sum(fit$withinss)
}
plot(1:10, wss, type = "b")

```

* Choose a k and cluster the data

```{r}

# We can choose a k = 4, 5 or 6

k.means.cluster = kmeans(scaled.crime.data, centers = 4)

```

* Visualise the clusters by plotting the data points on the first two principal components

```{r, fig.height=5, fig.width=8}

fviz_cluster(k.means.cluster, scaled.crime.data)

```

